version: '3.8'

services:

  # Single MongoDB instance (replacing sharded cluster)
  mongodb:
    image: mongo:5.0
    container_name: finance_mongodb
    hostname: mongodb
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: admin
    volumes:
      - mongodb_data:/data/db
    networks:
      - finance_network
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo --quiet || exit 0
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped

  # MongoDB setup service (simplified for single instance)
  mongo-setup:
    build:
      context: .
      dockerfile: ./mongo-setup/Dockerfile
    container_name: finance_mongo_setup
    hostname: mongo-setup
    networks:
      - finance_network
    environment:
      MONGO_ROOT_USERNAME: ${MONGO_ROOT_USERNAME}
      MONGO_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGODB_EXTRA_FLAGS: --quiet
      MONGO_INITDB_DATABASE: admin
    depends_on:
      mongodb:
        condition: service_healthy
    restart: "no"
    command: python3 /scripts/mongo_init.py
  # Zookeeper Ensemble
  zookeeper1:
    image: confluentinc/cp-zookeeper:7.2.0
    hostname: zookeeper1
    container_name: finance_zookeeper1
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888
    networks:
      - finance_network
    restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "echo stat | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Kafka Broker 1
  kafka-broker1:
    image: confluentinc/cp-kafka:7.2.0
    hostname: kafka-broker1
    container_name: finance_kafka_broker1
    depends_on:
      zookeeper1:
        condition: service_healthy
    ports:
      - '9092:9092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper1:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker1:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - finance_network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 40s # Increased start_period for Kafka
    restart: unless-stopped

  kafka-topic-setup:
    build:
      context: .
      dockerfile: ./kafka-consumer/Dockerfile # Reuses kafka-consumer's build environment
    container_name: finance_kafka_topic_setup
    hostname: kafka-topic-setup
    networks:
      - finance_network
    env_file:
      - .env # For KAFKA_BOOTSTRAP_SERVERS and topic names
    command: ["python", "/app/setup_topics.py"] # Assumes setup_topics.py is in /app
    depends_on:
      kafka-broker1:
        condition: service_healthy # Wait for Kafka broker to be healthy
      zookeeper1: # Also depends on Zookeeper for Kafka to be truly ready
        condition: service_healthy
    restart: "no" # Run once and exit

  # Spark Master
  spark-master:
    build:
      context: .
      dockerfile: ./docker/spark.Dockerfile
    container_name: finance_spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_CONF_DIR=/spark/conf
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./spark-conf:/spark/conf
    networks:
      - finance_network
    restart: unless-stopped

  # Spark Worker 1
  spark-worker1:
    build:
      context: .
      dockerfile: ./docker/spark.Dockerfile
    container_name: finance_spark_worker1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_CONF_DIR=/spark/conf
    ports:
      - "8081:8081"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./spark-conf:/spark/conf
    networks:
      - finance_network
    depends_on:
      - spark-master
    restart: unless-stopped

  # Elasticsearch Cluster
  elasticsearch-master:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.3.3
    container_name: finance_elasticsearch_master # This service will now be the single ES node
    environment:
      - node.name=es-single-node                 # Node name for the single instance
      - cluster.name=finance-es-cluster
      - discovery.type=single-node             # Critical for single-node operation
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=true              # Keep security enabled as Kibana uses it
      - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD}
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - es_master_data:/usr/share/elasticsearch/data # This volume will store all data
    ports:
      - "9200:9200"                            # HTTP port
      - "9300:9300"                            # Transport port
    networks:
      - finance_network
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:${ELASTICSEARCH_PASSWORD} http://localhost:9200/_cluster/health | grep -vq '\"status\":\"red\"'"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    restart: unless-stopped

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.3.3
    container_name: finance_kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch-master:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD}
    ports:
      - "${KIBANA_PORT}:5601"
    networks:
      - finance_network
    depends_on:
      - elasticsearch-master
    restart: unless-stopped

  dashboard-importer:
    build:
      context: .
      dockerfile: ./dashboards/Dockerfile
    container_name: finance_dashboard_importer
    hostname: dashboard-importer
    networks:
      - finance_network
    volumes:
      - ./logs:/app/logs
    depends_on:
      kibana:
        condition: service_started # The import script has its own wait logic for Kibana API
      elasticsearch-master:
        condition: service_healthy
    restart: "no"

  # Crawler Service
  crawler:
    build:
      context: .
      dockerfile: ./crawler/Dockerfile
    container_name: finance_crawler
    volumes:
      - ./logs:/app/logs
      - ./configs:/app/configs
    env_file:
      - .env
    networks:
      - finance_network
    depends_on:
      - mongodb
      - kafka-broker1

  # Kafka Consumer Service
  kafka-consumer:
    build:
      context: .
      dockerfile: ./kafka-consumer/Dockerfile
    container_name: finance_kafka_consumer
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    env_file:
      - .env
    networks:
      - finance_network
    depends_on:
      - kafka-broker1
      - mongodb

  # ETL Service
  etl:
    build:
      context: .
      dockerfile: ./spark-job/Dockerfile
    container_name: finance_etl
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./configs:/app/configs
    env_file:
      - .env
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - HADOOP_CONF_DIR=/etc/hadoop/conf
      - YARN_CONF_DIR=/etc/hadoop/conf
    networks:
      - finance_network
    depends_on:
      - spark-master
      - spark-worker1
      - mongodb

  # Scheduler Service
  scheduler:
    build:
      context: .
      dockerfile: ./docker/scheduler.Dockerfile
    container_name: finance_scheduler
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data:/app/data
      - ./logs:/app/logs
      - ./configs:/app/configs
    env_file:
      - .env
    networks:
      - finance_network
    depends_on:
      - mongodb
      - spark-master
      - elasticsearch-master
    restart: unless-stopped

networks:
  finance_network:
    name: ${NETWORK_NAME}

volumes:
  # MongoDB volume (single instance)
  mongodb_data:
  
  
  # Elasticsearch volumes
  es_master_data: # Volume for the single Elasticsearch node
  # es_data1_data, es_data2_data, and es_data3_data were removed with ES cluster simplification
